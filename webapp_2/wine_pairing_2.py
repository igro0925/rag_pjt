from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnableLambda
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore


from dotenv import load_dotenv
import os

load_dotenv(override=True, dotenv_path="../.env")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")
PINECONE_NAMESPACE = os.getenv("PINECONE_NAMESPACE")

# LLMì„ í†µí•œ ìš”ë¦¬ ì •ë³´ ì„¤ëª…
# 1. í•¨ìˆ˜ ì •ì˜ : ì´ë¯¸ì§€ -> ìš”ë¦¬ëª…, í’ë¯¸ ì„¤ëª… ì¶œë ¥
def describe_dish_flavor(input_data):

    prompt = ChatPromptTemplate([
        ("system", """
        You are a culinary expert who analyzes food images.
        When a user provides an image of a dish,
        identify the commonly recognized name of the dish, and
        clearly and concisely describe its flavor, focusing on the cooking method, texture, aroma, and balance of taste.
        If there is any uncertainty, base your analysis on the most likely dish, avoid definitive claims, and maintain a professional, expert tone.
        """),
        HumanMessagePromptTemplate.from_template([
            {"text": """ì•„ë˜ì˜ ì´ë¯¸ì§€ì˜ ìš”ë¦¬ì— ëŒ€í•œ ìš”ë¦¬ëª…ê³¼ ìš”ë¦¬ì˜ í’ë¯¸ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
            ì¶œë ¥í˜•íƒœ :
            ìš”ë¦¬ëª…:
            ìš”ë¦¬ì˜ í’ë¯¸:
            """},
            {"image_url": "{image_url}"} # image_urlëŠ” ì •í•´ì¤˜ ìˆìŒ.        
        ])
    ])
    
    # llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.1,
        api_key=GOOGLE_API_KEY
    )
    output_parser = StrOutputParser()
    
    chain = prompt | llm | output_parser

    return chain

# 2. í•¨ìˆ˜ ì •ì˜ : ìš”ë¦¬ ì„¤ëª… -> ìš”ë¦¬ ì„¤ëª…, ì™€ì¸ ì¶”ì²œ(Top-5)
# ìš”ë¦¬ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ top-5 ê²€ìƒ‰ê²°ê³¼ë¥¼ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def search_wines(query):
    embedding = OpenAIEmbeddings(
         model = OPENAI_EMBEDDING_MODEL
    )
    
    # ë²¡í„° dbì—ì„œ ìœ ì‚¬ë„ê³„ì‚°, top-5 ê²€ìƒ‰
    # ë²¡í„° db ê°ì²´ ìƒì„±
    vector_db = PineconeVectorStore(
        embedding = embedding,  # ì§ˆë¬¸ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ê°€ ìƒì„±ë¨
        index_name = PINECONE_INDEX_NAME ,
        namespace = PINECONE_NAMESPACE
    )
    # ë²¡í„° dbì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ, top-5 ê²€ìƒ‰í•˜ê¸°
    results = vector_db.similarity_search(query, k=5)  # top-5 ê²€ìƒ‰

    context = "\n".join([doc.page_content for doc in results])    

    # í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œ ìª½ìœ¼ë¡œ query, top-5ì˜ ê²€ìƒ‰ ê²°ê³¼ì— í•„í„°ë§í•œ ê²°ê³¼ë¥¼ ë¦¬í„´í•¨
    return {
        "query": query,
        "wine_reviews": context
    }

# í•¨ìˆ˜3 (r3). ìš”ë¦¬ì„¤ëª…, top-5ì˜ context ì…ë ¥ ë°›ê³  -> ìš”ë¦¬ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì¶”ì²œ
def recommend(input_data):
    prompt = ChatPromptTemplate([
    ("system", """
    ğŸ· Wine Sommelier â€“ System Prompt (Short / Optimized)
    You are a professional wine sommelier specialized in food and wine pairing.
    When responding, you:
    - Analyze food characteristics (ingredients, cooking method, sauce, flavor intensity)
    - Consider wine structure (acidity, tannin, sweetness, body, alcohol)
    - Apply pairing logic (balance, contrast, complement, intensity matching)
    You always:
    - Explain why a pairing works
    - Adapt recommendations to the customerâ€™s taste, budget, and occasion
    - Use clear, accessible language and avoid unnecessary jargon
    Your goal:
    Recommend wine pairings that create harmony between food and wine and maximize the customerâ€™s enjoyment.
        """),
        ("human", """ ì•„ë˜ì˜ ì™€ì¸ë¦¬ë·° ë‚´ìš©ì—ì„œë§Œ ì¶”ì²œì„ í•´ì¤˜ 
        ìš”ë¦¬ ì„¤ëª… : {query}
        ì™€ì¸ ë¦¬ë·° : {wine_reviews}

        ë‹µë³€ì€ jsonìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•´ ì£¼ì„¸ìš”.
        recommend_wine:
        recommend_reason:
        """)
    ])

    llm = ChatOpenAI(
        model='gpt-4o-mini',
        temperature=0.1,
        api_key=OPENAI_API_KEY
    )
    # str íŒŒì„œ
    # output_parser = StrOutputParser()

    # json íŒŒì„œ
    output_parser = JsonOutputParser()

    # pipeline : ë°ì´í„°ì˜ íë¦„
    chain = prompt | llm | output_parser

    return chain

# í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê¸°
def wine_pair_main(img_url):
    # RunnableLambda ê°ì²´ ìƒì„±(ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì—°ê²°í•˜ê¸° ìœ„í•´)
    r1 = RunnableLambda(describe_dish_flavor)
    r2 = RunnableLambda(search_wines)
    r3 = RunnableLambda(recommend)

    # chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°
    chain = r1 | r2 | r3

    # RunnableLambdaë¥¼ í†µí•œ í•¨ìˆ˜ ì‹¤í–‰
    input_data = {
        "image_url": img_url
    }

    res = chain.invoke(input_data)
    # print(res)
    return res

# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    print(__name__)
    print("-"*30)
    img_url = "https://thumbnail.coupangcdn.com/thumbnails/remote/492x492ex/image/vendor_inventory/9d0d/fd3f0d77757f64b2eba0905dcdd85051932ec1ab5e6afc0c3246f403fabc.jpg"
    result = wine_pair_main(img_url)
    print(result)