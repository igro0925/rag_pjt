{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c561b0",
   "metadata": {},
   "source": [
    "# RAG로 AI소믈리에 wine pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e2d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_EMBEDDING_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_NAMESPACE = os.getenv(\"PINECONE_NAMESPACE\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062f1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c838e",
   "metadata": {},
   "source": [
    "# LLM을 통한 요리 정보 해석\n",
    "- 이미지 -> 맛과 풍미 (image to text)\n",
    "- 입력 : 요리 이미지(url)\n",
    "- 출력 : 요리명, 요리에 대한 풍미 설명\n",
    "- 함수로 정의한 다음, RunnableLambda로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d84da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인과 페어링되는 음식\n",
    "def describe_dish_prompt(input_type):\n",
    "\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\n",
    "            \"system\", \"\"\"\n",
    "                You are a world-class gourmet and food connoisseur who has tasted cuisines from every culture and era.\n",
    "                You have an exceptional ability to identify dishes from visual cues alone and to describe flavors with vivid, sensory language.\n",
    "\n",
    "                Given an image of a dish, do the following:\n",
    "\n",
    "                1. Identify the most likely name of the dish.\n",
    "                - If the exact name is uncertain, suggest the closest well-known dish or culinary category.\n",
    "                2. Briefly describe the origin or culinary style (e.g., Chinese banquet cuisine, Italian rustic cooking, modern fusion).\n",
    "                3. Describe the flavor profile in rich, evocative detail, including:\n",
    "                - Dominant tastes (umami, sweetness, saltiness, acidity, bitterness)\n",
    "                - Aromas and sauces\n",
    "                - Texture and mouthfeel\n",
    "                - Balance and depth of flavor\n",
    "                4. Write as if you have personally eaten this dish many times.\n",
    "\n",
    "                Tone and style guidelines:\n",
    "                - Sophisticated, vivid, and expressive\n",
    "                - Sensory-focused (taste, aroma, texture)\n",
    "                - Confident but not speculative\n",
    "                - Avoid mentioning the image itself; speak as a gourmet describing the dish directly\n",
    "\n",
    "                Output format:\n",
    "\n",
    "                Dish Name:\n",
    "                Culinary Style / Origin:\n",
    "                Flavor Description:\n",
    "\n",
    "            \"\"\"),\n",
    "        HumanMessagePromptTemplate.from_template([\n",
    "            {\"text\": \"\"\"아래의 이미지의 요리에 대한 요리명과 요리의 풍미를 설명해 주세요.\n",
    "             출력형태 :\n",
    "             요리명 : \n",
    "             풍미 설명 :\n",
    "             \"\"\"},\n",
    "            {\"image_url\": \"{image_url}\"} # image_url는 정해져 있음.\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0.1,\n",
    "        api_key=GEMINI_API_KEY\n",
    "    )\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ddd0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 함수를 전달인자로 넣기\n",
    "runnable_1 = RunnableLambda(describe_dish_prompt)\n",
    "\n",
    "# RunnableLambda를 통한 함수 실행\n",
    "input_data = {\"image_url\": \"https://postfiles.pstatic.net/MjAyNDAyMTRfMTYx/MDAxNzA3OTEzODI5NDYx.LBvJwuKNKG2Sg6z61m0GwwXClLZ2AtRggm1oq_aGLFkg.tpalMG_Xm2GxJx7JbTfdN_PZ4xXBZky7Y-2lnbokHCcg.JPEG.alswl0224/%EC%A0%84%EA%B0%80%EB%B3%B5_(2).jpg?type=w966\"}\n",
    "response = runnable_1.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2963b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요리명 : 팔보채 (Palbochae)\n",
      "풍미 설명 :\n",
      "이 요리는 테이블에 놓이는 순간부터 그 화려하고 풍성한 향으로 미식가의 마음을 사로잡습니다. 바다의 신선함과 흙내음 가득한 버섯의 깊이, 그리고 은은한 생강과 마늘 향이 어우러져 코끝을 간지럽히죠. 모든 재료가 황금빛 윤기 나는 소스에 탐스럽게 뒤덮여 있어, 그 모습만으로도 이미 한 폭의 걸작입니다.\n",
      "\n",
      "입안에 처음 닿는 순간, 바다의 진귀한 보물들과 귀한 표고버섯이 선사하는 압도적인 감칠맛, 즉 우마미가 혀끝을 지배합니다. 이 깊은 풍미는 새우, 가리비, 그리고 촉촉한 고급 생선살에서 우러나오는 섬세하고 자연스러운 단맛과 절묘하게 균형을 이룹니다. 소스는 단순한 양념이 아닌, 간장과 굴 소스의 농후한 풍미를 기반으로 한 걸작입니다. 은근한 단맛이 더해져 감칠맛을 증폭시키고, 자극적이지 않으면서도 미묘하게 감도는 향신료의 온기가 미각을 부드럽게 감싸 안습니다. 벨벳처럼 부드러운 소스는 입안 가득 충만한 만족감을 주면서도 전혀 부담스럽지 않게 모든 재료를 완벽하게 감싸 안습니다.\n",
      "\n",
      "식감 또한 이 요리의 백미입니다. 생선살은 더할 나위 없이 부드러워 입안에서 사르르 녹아내리고, 칼집을 넣어 섬세하게 손질된 오징어는 쫄깃하면서도 야들야들한 탄력을 선사합니다. 가리비는 비단처럼 매끄러운 식감을 자랑하며, 연근은 예상치 못한 아삭함으로 풍성한 소스 속에서 상큼한 존재감을 드러냅니다. 두툼한 표고버섯은 씹을 때마다 묵직한 육즙과 함께 흙의 깊은 풍미를 터뜨리며 소스를 한껏 머금어 더욱 진한 맛을 내고, 초록빛 완두콩은 톡 터지는 신선함으로 입안을 리프레시해 줍니다. 부드러움, 쫄깃함, 아삭함 등 다채로운 식감의 조화가 매 순간 새로운 즐거움을 선사하며, 한입 한입이 미각의 탐험과도 같습니다.\n",
      "\n",
      "이 팔보채는 바다의 풍요로움과 땅의 보물이 만나 빚어낸 깊이와 균형이 완벽한 조화를 이루는, 맛과 향, 식감 모든 면에서 잊을 수 없는 미식 경험을 선사하는 진정한 축제의 요리입니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4622603",
   "metadata": {},
   "source": [
    "# 요리에 가장 잘 어울리는 와인 top 5 검색\n",
    "- pinecone 벡터 db 저장되어 있음\n",
    "- index : wine-review2\n",
    "- namespace : wine-review2-namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf68603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 프롬프트 vector화, 유사도 높은 top k개 문서 검색\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a039214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 프롬프트: 요리명 : 팔보채 (Palbochae)\n",
      "풍미 설명 :\n",
      "이 요리는 테이블에 놓이는 순간부터 그 화려하고 풍성한 향으로 미식가의 마음을 사로잡습니다. 바다의 신선함과 흙내음 가득한 버섯의 깊이, 그리고 은은한 생강과 마늘 향이 어우러져 코끝을 간지럽히죠. 모든 재료가 황금빛 윤기 나는 소스에 탐스럽게 뒤덮여 있어, 그 모습만으로도 이미 한 폭의 걸작입니다.\n",
      "\n",
      "입안에 처음 닿는 순간, 바다의 진귀한 보물들과 귀한 표고버섯이 선사하는 압도적인 감칠맛, 즉 우마미가 혀끝을 지배합니다. 이 깊은 풍미는 새우, 가리비, 그리고 촉촉한 고급 생선살에서 우러나오는 섬세하고 자연스러운 단맛과 절묘하게 균형을 이룹니다. 소스는 단순한 양념이 아닌, 간장과 굴 소스의 농후한 풍미를 기반으로 한 걸작입니다. 은근한 단맛이 더해져 감칠맛을 증폭시키고, 자극적이지 않으면서도 미묘하게 감도는 향신료의 온기가 미각을 부드럽게 감싸 안습니다. 벨벳처럼 부드러운 소스는 입안 가득 충만한 만족감을 주면서도 전혀 부담스럽지 않게 모든 재료를 완벽하게 감싸 안습니다.\n",
      "\n",
      "식감 또한 이 요리의 백미입니다. 생선살은 더할 나위 없이 부드러워 입안에서 사르르 녹아내리고, 칼집을 넣어 섬세하게 손질된 오징어는 쫄깃하면서도 야들야들한 탄력을 선사합니다. 가리비는 비단처럼 매끄러운 식감을 자랑하며, 연근은 예상치 못한 아삭함으로 풍성한 소스 속에서 상큼한 존재감을 드러냅니다. 두툼한 표고버섯은 씹을 때마다 묵직한 육즙과 함께 흙의 깊은 풍미를 터뜨리며 소스를 한껏 머금어 더욱 진한 맛을 내고, 초록빛 완두콩은 톡 터지는 신선함으로 입안을 리프레시해 줍니다. 부드러움, 쫄깃함, 아삭함 등 다채로운 식감의 조화가 매 순간 새로운 즐거움을 선사하며, 한입 한입이 미각의 탐험과도 같습니다.\n",
      "\n",
      "이 팔보채는 바다의 풍요로움과 땅의 보물이 만나 빚어낸 깊이와 균형이 완벽한 조화를 이루는, 맛과 향, 식감 모든 면에서 잊을 수 없는 미식 경험을 선사하는 진정한 축제의 요리입니다.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m query = response\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m사용자 프롬프트:\u001b[39m\u001b[33m\"\u001b[39m, query)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mvector_db\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:676\u001b[39m, in \u001b[36mPineconeVectorStore.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, namespace, **kwargs)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    658\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    659\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    663\u001b[39m     **kwargs: Any,\n\u001b[32m    664\u001b[39m ) -> List[Document]:\n\u001b[32m    665\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[32m    666\u001b[39m \n\u001b[32m    667\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    674\u001b[39m \u001b[33;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[32m    675\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:543\u001b[39m, in \u001b[36mPineconeVectorStore.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, namespace, **kwargs)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search_with_score\u001b[39m(\n\u001b[32m    524\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    525\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    529\u001b[39m     **kwargs: Any,\n\u001b[32m    530\u001b[39m ) -> List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[32m    532\u001b[39m \n\u001b[32m    533\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    540\u001b[39m \u001b[33;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.similarity_search_by_vector_with_score(\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    544\u001b[39m         k=k,\n\u001b[32m    545\u001b[39m         \u001b[38;5;28mfilter\u001b[39m=\u001b[38;5;28mfilter\u001b[39m,\n\u001b[32m    546\u001b[39m         namespace=namespace,\n\u001b[32m    547\u001b[39m         **kwargs,\n\u001b[32m    548\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:759\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_query\u001b[39m\u001b[34m(self, text, **kwargs)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[32m    750\u001b[39m \n\u001b[32m    751\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m \u001b[33;03m    Embedding for the text.\u001b[39;00m\n\u001b[32m    757\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    758\u001b[39m \u001b[38;5;28mself\u001b[39m._ensure_sync_client_available()\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:709\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;66;03m# Unconditionally call _get_len_safe_embeddings to handle length safety.\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[38;5;66;03m# This could be optimized to avoid double work when all texts are short enough.\u001b[39;00m\n\u001b[32m    708\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:576\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;66;03m# Make API call with this batch\u001b[39;00m\n\u001b[32m    575\u001b[39m batch_tokens = tokens[i:batch_end]\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mbatch_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    578\u001b[39m     response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# 요리에 대한 풍미(설명)이 들어오면,\n",
    "# 벡터 DB에 인덱싱할 때 사용한 임베딩 모델과 동일한 모델로 임베딩 벡터화 수행\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=OPENAI_EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "# Pinecone 벡터 db 객체 생성\n",
    "vector_db = PineconeVectorStore(\n",
    "    index_name=PINECONE_INDEX_NAME,\n",
    "    embedding=embedding_model,\n",
    "    namespace=PINECONE_NAMESPACE\n",
    ")\n",
    "\n",
    "# 벡터 DB에서 유사도 높은 top k개 문서 검색\n",
    "query = response\n",
    "print(\"사용자 프롬프트:\", query)\n",
    "print(\"-\"*50)\n",
    "vector_db.similarity_search(query, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
